## Big O Notation

- Origin: Popularised by Donald Knuth, Big O notation has its roots in number theory.
- Purpose: Big O notation describes the upper limit of the time complexity of an algorithm, allowing for a comparison of the worst-case scenarios.

## Complexity Examples
- **Constant Time Complexity ($O(1)$)**: The time required remains constant irrespective of the input size. For example, accessing the first element of a list.
- **Linear Time Complexity ($O(n)$)**: The time required grows linearly with the input size. For example, finding an item in an unsorted list.

## Algorithm Complexity
- **Insertion Sort**: Worst-case performance is $O(n^2)$. It's efficient for small data sets but less efficient for larger lists.
- **Quick Sort**: Worst-case performance is $O(n^2)$, but the average performance is $O(n \log n)$. Quick Sort is generally faster due to this average case, especially for large datasets.

- Cheatsheet for reference: [Big O](https://www.bigocheatsheet.com/)
