
### Alexnet

Key aspect of this model
- ReLU was used instead of sigmoid or tanh
- Specialized normalization layers
- PCA based data augmentation
- First network used Dropout
- This made use of Ensembling

### VGG

Key aspects
- 3x3 conv - stride 1, padding 1
- 2x2 max pooling (stride 2)
- Very large number of parameters

### Inception

Key aspects of this model
- There are repeated blocks

### Efficient Nets

This has lesser parameters, but performs much better


