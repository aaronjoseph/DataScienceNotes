HDFS - Hadoop Distributed File System is a distributed file system designed to run on commodity hardware. HDFS is highly fault-tolerant and is designed to work on low-cost hardware. 

This is suited for batch processing, data access has high throughput rather than low latency. And can support large amount of data.

`Name Node`

Manages the overall files system
Stores the 
- Directory structure
- Metadata of the files

`Data Node`

Physically stores the data in the cluster
